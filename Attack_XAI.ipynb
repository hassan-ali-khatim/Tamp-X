{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import general_utils\n",
    "import tampering_utils\n",
    "import xai_utils\n",
    "import generate_explanations, visualize_results\n",
    "importlib.reload(general_utils)\n",
    "importlib.reload(tampering_utils)\n",
    "importlib.reload(xai_utils)\n",
    "importlib.reload(generate_explanations)\n",
    "importlib.reload(visualize_results)\n",
    "from generate_explanations import *\n",
    "from general_utils import train_and_save_model\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_data = \"data\"\n",
    "data_names = [\"kaggle\"]\n",
    "max_len = 100\n",
    "custom_dropouts = [None, 10, 20, 30, 40, 50]\n",
    "batch_size = 64\n",
    "seqs_count = 24\n",
    "path = \"all_results/results1/\"\n",
    "\n",
    "explain_for_dataset = {\n",
    "    \"kaggle\": explain_for_kaggle,\n",
    "    \"AG\": explain_for_ag,\n",
    "    \"toxic\": explain_for_toxic\n",
    "}\n",
    "\n",
    "# 0 for training\n",
    "# 1 for explaining\n",
    "mode = 2\n",
    "\n",
    "for data_name in data_names:\n",
    "    data = load_tokenized_data(batch_size=batch_size, data_name=data_name, make_even_flag=True)\n",
    "    if mode==0:\n",
    "        train_and_save_model(path, max_len=max_len, path_data=\"data\", data_name=data_name, \n",
    "                             custom_dropouts=custom_dropouts, batch_size=batch_size, epochs=5)\n",
    "    elif mode==1:\n",
    "        explain_for_dataset[data_name](data, seqs_count, path=path, custom_dropouts=custom_dropouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from visualize_results import show_for_kaggle\n",
    "\n",
    "# #30, 4\n",
    "# #None, [4,5,8,11,23]\n",
    "# # 50, [2,23]\n",
    "\n",
    "# indices = np.where(np.argmax(data[1], axis=1) == 0)[0]\n",
    "# print(indices)\n",
    "# indices = indices[np.where(indices<seqs_count)]\n",
    "# contributions = show_for_kaggle(\n",
    "#     path, 'kaggle', data, [4,5,8,11,23], [\"lime\"], custom_dropouts=([None])\n",
    "# );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figures = True\n",
    "fig_acc = None\n",
    "\n",
    "compute_accuracies(data, data_name=data_name, path=path)\n",
    "fig_acc = plot_accuracies(data_name=data_name, path=path)\n",
    "\n",
    "# if save_figures:\n",
    "#     fig_acc.savefig(path+'Figures/accuracies_'+data_name+'_'+str(max_len)+'.pdf', layout='tight')\n",
    "#     plt.close(fig_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(generate_explanations)\n",
    "from generate_explanations import *\n",
    "\n",
    "\n",
    "save_figures = False\n",
    "figs_cs, figs_l1, figs_l2 = None, None, None\n",
    "\n",
    "figs_cs, scores = plot_cosine_similarities(path=path, data_name=data_name, seqs_count=seqs_count)\n",
    "# figs_l1 = plot_L_Norms(1, path=path, data_name=data_name)\n",
    "# figs_l2 = plot_L_Norms(2, path=path, data_name=data_name)\n",
    "\n",
    "\n",
    "if save_figures:\n",
    "    with PdfPages(path+'Figures/'+\"hybrid_\"+data_name+\"_\"+str(max_len)+'cosine_similarity.pdf') as pdf:\n",
    "        for fig in figs_cs:\n",
    "            plt.figure(fig.number)\n",
    "            pdf.savefig(layout=\"tight\")\n",
    "            plt.close(fig)\n",
    "\n",
    "    with PdfPages(path+'Figures/'+\"hybrid_\"+data_name+\"_\"+str(max_len)+'L1_norms.pdf') as pdf:\n",
    "        for fig in figs_l1:\n",
    "            plt.figure(fig.number)\n",
    "            pdf.savefig(layout=\"tight\")\n",
    "            plt.close(fig)\n",
    "        \n",
    "\n",
    "    with PdfPages(path+'Figures/'+\"hybrid_\"+data_name+\"_\"+str(max_len)+'L2_norms.pdf') as pdf:\n",
    "        for fig in figs_l2:\n",
    "            plt.figure(fig.number)\n",
    "            pdf.savefig(layout=\"tight\")\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figures = True\n",
    "is_remove = False\n",
    "num_words_s = [50, 90]#None, 10, 30, 40, 50]\n",
    "\n",
    "for num_words in num_words_s:\n",
    "    figs_da = None  \n",
    "    figs_da = plot_descriptive_accuracies(data, path=path, data_name=data_name, seqs_count=seqs_count,\n",
    "                                          num_words=num_words, is_remove=is_remove)\n",
    "\n",
    "    if save_figures:\n",
    "        with PdfPages(path+'Figures/'+\"hybrid_\"+data_name+\"_\"+str(max_len)+'_descriptive_accuracy_'+str(num_words)+'_'+str(is_remove)+'.pdf') as pdf:\n",
    "            plt.tight_layout()\n",
    "            for fig in figs_da:\n",
    "                plt.figure(fig.number)\n",
    "                pdf.savefig(layout=\"tight\")\n",
    "                plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tampering_utils import plot_activation_function, inverse_sigmoid, hard_sigmoid, sinusoidal_sigmoid\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "class inverse_sigmoid2(keras.layers.Layer):\n",
    "    def __init__(self, constant1=10, constant2=1, limits=[0, 0]):\n",
    "        super(inverse_sigmoid2, self).__init__()\n",
    "        self.constant1 = constant1\n",
    "        self.constant2 = constant2\n",
    "        self.limits = np.mean(limits)\n",
    "\n",
    "    def sigmoid(self, x, constant):\n",
    "        return 1/ (1 + (tf.exp(-constant * x)))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        term_1 = self.sigmoid(-(inputs-self.limits), constant=self.constant1) * \\\n",
    "            (-0.6 + self.sigmoid(-(inputs-self.limits), constant=self.constant2))\n",
    "        term_2 = self.sigmoid(inputs-self.limits, constant=self.constant1) * \\\n",
    "            (0.6 + self.sigmoid(-(inputs-self.limits), constant=self.constant2))\n",
    "        outputs = term_1 + term_2\n",
    "        return outputs\n",
    "\n",
    "activation_functions = [inverse_sigmoid, hard_sigmoid, sinusoidal_sigmoid]\n",
    "figs = []\n",
    "for activation_function in activation_functions:\n",
    "    values, _, fig, model = plot_activation_function(activation_function, return_model=True)\n",
    "    figs.append(fig)\n",
    "\n",
    "# model.summary()\n",
    "# # input_seqs = values#np.arange(-10, 10, 0.1)\n",
    "# model_in = values.reshape(-1, 1)\n",
    "# model_in = tf.constant(model_in)\n",
    "# print(model_in.shape)\n",
    "# with tf.GradientTape() as tape:\n",
    "#     tape.watch(model_in)\n",
    "#     model_out = model(model_in)\n",
    "#     grads = tape.gradient(model_out, model_in)\n",
    "#     # print(grads)\n",
    "# grads = grads.numpy()\n",
    "# plt.plot(values, grads[:,0])\n",
    "# plt.ylim([-1, 1])\n",
    "\n",
    "# grads.shape\n",
    "\n",
    "\n",
    "with PdfPages(path+'Figures/activation_functions.pdf') as pdf:\n",
    "    for fig in figs:\n",
    "        plt.figure(fig.number)\n",
    "        pdf.savefig(layout='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr_seq, y_train, x_val_seq, y_test, tokenizer, size_of_vocabulary = data\n",
    "activations = [None, inverse_sigmoid, hard_sigmoid, sinusoidal_sigmoid]\n",
    "activation_names = [\"No Tampering\", \"Inverse Sigmoid\", \"Hard Sigmoid\", \"Sinusoidal Sigmoid\"]\n",
    "\n",
    "figures_all = []\n",
    "for custom_dropout in custom_dropouts:\n",
    "    print(\"dropout_value: \", custom_dropout)\n",
    "    model = load_trained_model(path, size_of_vocabulary, data_name=data_name, \n",
    "                            num_classes=y_train.shape[1], custom_dropout=custom_dropout)\n",
    "    model_unmasked = inference_model(model, include_softmax=False)\n",
    "    min_threshold, max_threshold, fig = visualize_activations(model_unmasked, x_tr_seq[:100], figure=True, bins=100)\n",
    "    figures_all.append(fig)\n",
    "    \n",
    "    # accuracies = []\n",
    "    # for i in range(len(activations)):\n",
    "    #     model_tampered = inference_model(model, tampering_activation=activations[i], \n",
    "    #                             tampering_limits=([min_threshold, max_threshold]))\n",
    "    #     accuracies.append(model_tampered.evaluate(x_val_seq, y_test)[1])\n",
    "    \n",
    "with PdfPages(path+'Figures/logit_activations_'+data_name+'_'+str(max_len)+'.pdf') as pdf:\n",
    "    for fig in figures_all:\n",
    "        plt.figure(fig.number)\n",
    "        pdf.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(model_r):\n",
    "    print(np.argmax(model_r.predict(x_val_seq[5:10]), axis=1), model_r.predict(x_val_seq[5:10]))\n",
    "    print(\"==========================================\")\n",
    "\n",
    "print(np.mean([min_threshold, max_threshold]))\n",
    "for model_r in ([model, model_unmasked, model_tampered]):\n",
    "    check(model_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
